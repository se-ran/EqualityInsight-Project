{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, confusion_matrix, classification_report\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "_1ZwE6-d13fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 임금 격차(Wage_Gap)의 값 분포를 시각화"
      ],
      "metadata": {
        "id": "pN26VlOUXYZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(data['Wage_Gap'], bins=30, alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Distribution of Wage Gap Values\", fontsize=14)\n",
        "plt.xlabel(\"Wage Gap\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "data['Wage_Gap'].min(), data['Wage_Gap'].max()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "8d7TH873XYxZ",
        "outputId": "dc525e2b-447f-409e-a863-1fab1dcf68b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-125.607, 37.319)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 경사하강법(Gradient Descent)"
      ],
      "metadata": {
        "id": "8FS3RSpGDFLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_normalized = (X - np.mean(X)) / np.std(X)\n",
        "y_normalized = (y - np.mean(y)) / np.std(y)\n",
        "\n",
        "theta_0 = 0  # Intercept\n",
        "theta_1 = 0  # Slope\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "for _ in range(iterations):\n",
        "    y_pred = theta_0 + theta_1 * X_normalized.flatten()\n",
        "    error = y_pred - y_normalized\n",
        "    theta_0 -= learning_rate * (1/m) * np.sum(error)\n",
        "    theta_1 -= learning_rate * (1/m) * np.sum(error * X_normalized.flatten())\n",
        "\n",
        "theta_1_original = theta_1 * (np.std(y) / np.std(X))\n",
        "theta_0_original = np.mean(y) - theta_1_original * np.mean(X)\n",
        "\n",
        "gd_y_pred_original = theta_0_original + theta_1_original * X.flatten()\n",
        "gd_mse_original = mean_squared_error(y, gd_y_pred_original)\n",
        "\n",
        "updated_results = {\n",
        "    \"Updated Gradient Descent Intercept\": theta_0_original,\n",
        "    \"Updated Gradient Descent Slope\": theta_1_original,\n",
        "    \"Updated Gradient Descent MSE\": gd_mse_original,\n",
        "}\n",
        "updated_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obl4xAoGU4vm",
        "outputId": "fbd13b10-24f9-4515-8db4-f80791b5e526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Updated Gradient Descent Intercept': -2.2148964480208644,\n",
              " 'Updated Gradient Descent Slope': 0.5553886495386525,\n",
              " 'Updated Gradient Descent MSE': 248.27893576622967}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_data = pd.read_csv('grad_mod_data.csv')\n",
        "wage_data = pd.read_csv('wage_mod_data.csv')\n",
        "grad_data.head(), wage_data.head()"
      ],
      "metadata": {
        "id": "2vH347DG_c15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_data.rename(columns={'Country': 'ref_area.label', 'TIME': 'time', 'Value': 'grad_rate'}, inplace=True)\n",
        "wage_data.rename(columns={'obs_value': 'wage_gap'}, inplace=True)\n",
        "merged_data = pd.merge(grad_data, wage_data, on=['ref_area.label', 'time'], how='inner')\n",
        "merged_data.to_csv('Merged_data.csv', index=False)"
      ],
      "metadata": {
        "id": "cmhFrbHJFj66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing extreme values in the top and bottom 1% based on quantiles.\n",
        "filtered_data = merged_data[\n",
        "    (merged_data['wage_gap'] > merged_data['wage_gap'].quantile(0.01)) &\n",
        "    (merged_data['wage_gap'] < merged_data['wage_gap'].quantile(0.99)) &\n",
        "    (merged_data['grad_rate'] > merged_data['grad_rate'].quantile(0.01)) &\n",
        "    (merged_data['grad_rate'] < merged_data['grad_rate'].quantile(0.99))\n",
        "]\n",
        "\n",
        "filtered_data = pd.get_dummies(filtered_data, columns=['source.label'], drop_first=True)\n",
        "X = filtered_data[['grad_rate'] + [col for col in filtered_data.columns if col.startswith('source.label_')]]\n",
        "y = filtered_data['wage_gap']\n"
      ],
      "metadata": {
        "id": "eZoqdmVpDvgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 독립변수 (설명변수): grad_rate와 source.label_로 시작하는 원-핫 인코딩된 변수들 (대학 졸업률과 다양한 출처 레이블).\n",
        "#### 종속변수 (목표변수): wage_gap (임금 격차)."
      ],
      "metadata": {
        "id": "M3fcUcMgEj7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Machine Learning Model Tuning Process:\n",
        "\n",
        "## Initial Regression Model Comparison and Selection:\n",
        "- **XGBRegressor**:  \n",
        "  - **R²** = 0.7323  \n",
        "  - **RMSE** = 6.1634  \n",
        "  - **SSE** = 1367.5395  \n",
        "  - **Performance**: The best-performing model with the highest R² and lowest RMSE.  \n",
        "\n",
        "- **GradientBoostingRegressor**:  \n",
        "  - **R²** = 0.6751  \n",
        "  - **Performance**: Lower performance compared to XGBRegressor.  \n",
        "\n",
        "- **Random Forest Regressor**:  \n",
        "  - **R²** = 0.5929  \n",
        "  - **RMSE** = 7.5997  \n",
        "  - **Performance**: Relatively low performance.  \n",
        "\n",
        "- **CatBoostRegressor**:  \n",
        "  - **R²** = 0.5638  \n",
        "  - **Performance**: The worst performance among the models evaluated.  \n",
        "\n",
        "## Conclusion:\n",
        "▶ Based on its superior R² score and lowest RMSE, **XGBRegressor** was selected as the best regression model.  \n",
        "▶ Further performance improvements were attempted by optimizing XGBRegressor using **GridSearchCV** for hyperparameter tuning.  \n",
        "\n"
      ],
      "metadata": {
        "id": "ym-DPo7LCXgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBRegressor: Comparison Between Simple XGBoost and GridSearchCV-Optimized Model\n",
        "\n",
        "### Comparison of Simple XGBoost and Optimized Model\n",
        "- **Hyperparameter Optimization**:  \n",
        "  The optimized model was tuned using GridSearchCV, exploring combinations of `n_estimators`, `learning_rate`, `max_depth`, `subsample`, and `colsample_bytree` with 5-fold cross-validation.  \n",
        "  The best parameters were determined as:  \n",
        "  ```python\n",
        "  {\n",
        "      'colsample_bytree': 1.0,\n",
        "      'learning_rate': 0.1,\n",
        "      'max_depth': 7,\n",
        "      'n_estimators': 50,\n",
        "      'subsample': 0.8\n",
        "  }\n",
        "-  Performance:\n",
        "  The simple XGBoost model achieved slightly lower RMSE and higher R² than the optimized model.\n",
        "  However, this performance indicates a potential risk of overfitting to the specific dataset.\n",
        "\n",
        "- While the simple XGBoost model performed marginally better on the given data, the GridSearchCV-optimized model is more reliable for generalization due to its regularization and cross-validation-based parameter tuning."
      ],
      "metadata": {
        "id": "oNsrY-m8ohIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "SST = np.sum((y_test - np.mean(y_test))**2)\n",
        "SSR = np.sum((y_pred - np.mean(y_test))**2)\n",
        "SSE = np.sum((y_test - y_pred)**2)\n",
        "\n",
        "R_squared_manual = SSR / SST\n",
        "\n",
        "results = {\n",
        "    \"R² (sklearn)\": r2,\n",
        "    \"R² (manual)\": R_squared_manual,\n",
        "    \"SST (Total Sum of Squares)\": SST,\n",
        "    \"SSR (Regression Sum of Squares)\": SSR,\n",
        "    \"SSE (Sum of Squared Errors)\": SSE\n",
        "}\n",
        "\n",
        "print(f\"R² score: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oxtf-X4K2RX",
        "outputId": "7ff4d5fc-a581-40c7-b9c7-73784ea09494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² score: 0.7322525080371426\n",
            "RMSE: 6.163376463410965\n",
            "R² (sklearn): 0.7323\n",
            "R² (manual): 0.5843\n",
            "SST (Total Sum of Squares): 5107.5718\n",
            "SSR (Regression Sum of Squares): 2984.3728\n",
            "SSE (Sum of Squared Errors): 1367.5395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## GridSearchCV-Optimized XGBoost Model\n",
        "\n",
        "- **Performance Metrics**:\n",
        "  - **R² (sklearn)**: 0.7170  \n",
        "  - **R² (manual)**: 0.7163  \n",
        "  - **RMSE**: 6.3361  \n",
        "\n",
        "> Although the optimized model showed slightly lower R² and increased RMSE compared to the baseline, it demonstrated improved stability and generalization performance.\n",
        "\n",
        "- **SST, SSR, SSE Comparison**:\n",
        "  - **Simple Model**:  \n",
        "    SSR (2984.37) + SSE (1367.54) ≈ SST (5107.57)  \n",
        "  - **Optimized Model**:  \n",
        "    SSR (3658.69) + SSE (1445.26) ≈ SST (5107.57)  \n",
        "\n",
        "> The increase in SSR and decrease in SSE suggest that the optimized model has greater explanatory power.  \n"
      ],
      "metadata": {
        "id": "EoSoMN2BFBvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=XGBRegressor(random_state=42), param_grid=param_grid, scoring='r2', cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "SST = np.sum((y_test - np.mean(y_test))**2)\n",
        "SSR = np.sum((y_pred - np.mean(y_test))**2)\n",
        "SSE = np.sum((y_test - y_pred)**2)\n",
        "\n",
        "R_squared_manual = SSR / SST\n",
        "\n",
        "results = {\n",
        "    \"Best Parameters\": grid_search.best_params_,\n",
        "    \"R² (sklearn)\": r2,\n",
        "    \"R² (manual)\": R_squared_manual,\n",
        "    \"RMSE\": rmse,\n",
        "    \"SST\": SST,\n",
        "    \"SSR\": SSR,\n",
        "    \"SSE\": SSE\n",
        "}\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3t0G-PNui1k",
        "outputId": "12535198-006a-4436-e2ce-a70835c6ed8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.8}\n",
            "R² (sklearn): 0.7170\n",
            "R² (manual): 0.7163\n",
            "RMSE: 6.3361\n",
            "SST: 5107.5718\n",
            "SSR: 3658.69482421875\n",
            "SSE: 1445.2631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Outlier Removal Using IQR (Interquartile Range)\n",
        "\n",
        "- **Approach**:  \n",
        "  Outliers were removed using the IQR method.  \n",
        "\n",
        "- **Comparison**:  \n",
        "  Removing extreme values in the top and bottom 1% based on quantiles resulted in **better performance** than using the IQR method.\n"
      ],
      "metadata": {
        "id": "5ZCYC-qX9fI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    return df[(df[column] >= Q1 - 1.5 * IQR) & (df[column] <= Q3 + 1.5 * IQR)]\n",
        "\n",
        "filtered_data = remove_outliers(merged_data, 'grad_rate')\n",
        "filtered_data = pd.get_dummies(filtered_data, columns=['source.label'], drop_first=True)\n",
        "X = filtered_data[['grad_rate'] + [col for col in filtered_data.columns if col.startswith('source.label_')]]\n",
        "y = filtered_data['wage_gap']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R² score: {r2}\")\n",
        "\n",
        "# Filtering only wage gap: 0.53\n",
        "# Filtering both: 0.51\n",
        "# Filtering only grad_rate: 0.64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ePam3AAzR8",
        "outputId": "9bbe05bb-080b-45e5-93b1-02de06d70754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² score: 0.6436388402095885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing XGBoost Model Using Gaussian Noise and GridSearchCV\n",
        "\n",
        "- **Model Performance**:  \n",
        "  The model's **R² decreased** after applying this approach.\n",
        "\n",
        "- **Data Augmentation**:  \n",
        "  Added **5% Gaussian noise** to the training data (`X_train`) to enhance data diversity and improve the model's generalization performance.\n",
        "\n",
        "- **Hyperparameter Tuning**:  \n",
        "  Optimized the parameters using GridSearchCV, tuning `n_estimators`, `learning_rate`, `max_depth`, `subsample`, and `colsample_bytree`.  \n",
        "  The optimal parameters identified were:  \n",
        "  ```python\n",
        "  {\n",
        "      'colsample_bytree': 0.8,\n",
        "      'learning_rate': 0.2,\n",
        "      'max_depth': 7,\n",
        "      'n_estimators': 50,\n",
        "      'subsample': 0.8\n",
        "  }\n"
      ],
      "metadata": {
        "id": "rvdMuIGhxiYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def add_gaussian_noise(X, noise_level=0.01):\n",
        "    noise = np.random.normal(0, noise_level, X.shape)\n",
        "    return X + noise\n",
        "\n",
        "X_train_noisy = add_gaussian_noise(X_train, noise_level=0.05)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=XGBRegressor(random_state=42), param_grid=param_grid, scoring='r2', cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train_noisy, y_train)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "best_xgb.fit(X_train_noisy, y_train)\n",
        "\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "SST = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "SSR = np.sum((y_pred - np.mean(y_test)) ** 2)\n",
        "SSE = np.sum((y_test - y_pred) ** 2)\n",
        "R_squared_manual = SSR / SST\n",
        "\n",
        "results = {\n",
        "    \"Best Parameters\": grid_search.best_params_,\n",
        "    \"R² (sklearn)\": r2,\n",
        "    \"R² (manual)\": R_squared_manual,\n",
        "    \"RMSE\": rmse,\n",
        "    \"SST\": SST,\n",
        "    \"SSR\": SSR,\n",
        "    \"SSE\": SSE\n",
        "}\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzD7ilYTzqQJ",
        "outputId": "d40d1b37-6ba8-4413-c908-3da1982af266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.8}\n",
            "R² score: 0.3335\n",
            "RMSE: 9.7242\n",
            "R² (sklearn): 0.3335\n",
            "R² (manual): 0.3335\n",
            "SST (Total Sum of Squares): 5107.5718\n",
            "SSR (Regression Sum of Squares): 1090.5586\n",
            "SSE (Sum of Squared Errors): 3404.1439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing XGBoost Model Using Polynomial Features and GridSearchCV\n",
        "\n",
        "- **Polynomial Features**:  \n",
        "  Added second-degree polynomial features to the input data to model non-linear relationships.  \n",
        "\n",
        "- **Impact**:  \n",
        "  - The inclusion of polynomial features and hyperparameter optimization improved the model's explanatory power (SSR) and partially captured non-linear relationships.\n",
        "  - However, **R² slightly decreased**, and **RMSE increased**, indicating that the optimized model performed slightly less precise predictions compared to the original model.  \n"
      ],
      "metadata": {
        "id": "MHsmP5K35L_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=XGBRegressor(random_state=42), param_grid=param_grid, scoring='r2', cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "SST = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "SSR = np.sum((y_pred - np.mean(y_test)) ** 2)\n",
        "SSE = np.sum((y_test - y_pred) ** 2)\n",
        "R_squared_manual = SSR / SST\n",
        "\n",
        "results = {\n",
        "    \"Best Parameters\": grid_search.best_params_,\n",
        "    \"R² (sklearn)\": r2,\n",
        "    \"R² (manual)\": R_squared_manual,\n",
        "    \"RMSE\": rmse,\n",
        "    \"SST\": SST,\n",
        "    \"SSR\": SSR,\n",
        "    \"SSE\": SSE\n",
        "}\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNVW93rl38-U",
        "outputId": "6f52670f-949b-4660-fecc-7843d9f2c9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
            "R² score: 0.7176\n",
            "RMSE: 6.3300\n",
            "R² (sklearn): 0.7176\n",
            "R² (manual): 0.7176\n",
            "SST (Total Sum of Squares): 5107.5718\n",
            "SSR (Regression Sum of Squares): 4631.2075\n",
            "SSE (Sum of Squared Errors): 1442.4725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing XGBoost Model Using Bootstrap and GridSearchCV\n",
        "\n",
        "- **Bootstrapping**:  \n",
        "  New training datasets were generated from the original data using bootstrapping to enhance data diversity.  \n",
        "  While bootstrapping and hyperparameter optimization improved generalization performance, further improvement in R² and RMSE values is required.  \n",
        "\n",
        "- **Hyperparameter Tuning**:  \n",
        "  Optimization was performed using GridSearchCV with 5-fold cross-validation.  \n",
        "  The optimal parameters identified were:  \n",
        "  ```python\n",
        "  {\n",
        "      'colsample_bytree': 0.8,\n",
        "      'learning_rate': 0.2,\n",
        "      'max_depth': 3,\n",
        "      'n_estimators': 200,\n",
        "      'subsample': 1.0\n",
        "  }\n"
      ],
      "metadata": {
        "id": "0DVF3w2e2m3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_bootstrap, y_train_bootstrap = resample(X_train, y_train, n_samples=len(X_train), random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=XGBRegressor(random_state=42), param_grid=param_grid, scoring='r2', cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "\n",
        "best_xgb = grid_search.best_estimator_\n",
        "best_xgb.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "SST = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "SSR = np.sum((y_pred - np.mean(y_test)) ** 2)\n",
        "SSE = np.sum((y_test - y_pred) ** 2)\n",
        "R_squared_manual = 1 - (SSE / SST)\n",
        "\n",
        "results = {\n",
        "    \"Best Parameters\": grid_search.best_params_,\n",
        "    \"R² (sklearn)\": r2,\n",
        "    \"R² (manual)\": R_squared_manual,\n",
        "    \"RMSE\": rmse,\n",
        "    \"SST\": SST,\n",
        "    \"SSR\": SSR,\n",
        "    \"SSE\": SSE\n",
        "}\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HYiJHMO2nCV",
        "outputId": "d37fad0b-d713-42b5-fa33-d95f5afb7851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
            "R² score: 0.5555\n",
            "RMSE: 7.9411\n",
            "R² (sklearn): 0.5555\n",
            "R² (manual): 0.5555\n",
            "SST (Total Sum of Squares): 5107.5718\n",
            "SSR (Regression Sum of Squares): 6067.2139\n",
            "SSE (Sum of Squared Errors): 2270.2181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "-uGlnJkv7D7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "print(f\"Gradient Boosting R²: {r2_gb}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWqJuVFZPLdb",
        "outputId": "873629c1-ef81-4c65-e8c2-7b4622e8072a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting R²: 0.6750952846990046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Random Forest Regressor"
      ],
      "metadata": {
        "id": "OVWwpE526zft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kENvN3dZCQpk",
        "outputId": "f725b219-98dc-47e4-ba23-914c30166335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.5929\n",
            "Mean Squared Error: 57.7551\n",
            "Root Mean Squared Error: 7.5997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# CatBoostRegressor"
      ],
      "metadata": {
        "id": "EiuG0t4O6-nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "cat_model = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, random_state=42, verbose=0)\n",
        "cat_model.fit(X_train, y_train)\n",
        "y_pred_cat = cat_model.predict(X_test)\n",
        "r2_cat = r2_score(y_test, y_pred_cat)\n",
        "print(f\"CatBoost R²: {r2_cat}\")\n"
      ],
      "metadata": {
        "id": "CNbCl3PmPRTb",
        "outputId": "c385a8bc-b917-4270-f72b-5214238dcc78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost R²: 0.5637627251214996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fZynNRQzuaOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving Classification Problems Using Logistic Regression\n",
        "\n",
        "## Targeting `wage_gap`, which is typically a continuous variable.\n",
        "## A conversion process is required to transform `wage_gap` into a binary classification variable.\n",
        "### Class 0: Indicates the likelihood of lower wage inequality.\n",
        "### Class 1: Indicates the likelihood of higher wage inequality.\n"
      ],
      "metadata": {
        "id": "ffWJurEpghRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers (based on the 1st and 99th percentiles)\n",
        "filtered_data = merged_data[\n",
        "    (merged_data['wage_gap'] > merged_data['wage_gap'].quantile(0.01)) &\n",
        "    (merged_data['wage_gap'] < merged_data['wage_gap'].quantile(0.99)) &\n",
        "    (merged_data['grad_rate'] > merged_data['grad_rate'].quantile(0.01)) &\n",
        "    (merged_data['grad_rate'] < merged_data['grad_rate'].quantile(0.99))\n",
        "]\n",
        "\n",
        "# Convert 'source.label' to a categorical variable and apply one-hot encoding\n",
        "filtered_data = pd.get_dummies(filtered_data, columns=['source.label'], drop_first=True)\n",
        "\n",
        "# Transform 'wage_gap' into a binary classification value (assign 0 or 1 based on the median)\n",
        "median_wage_gap = filtered_data['wage_gap'].median()\n",
        "filtered_data['wage_gap_class'] = (filtered_data['wage_gap'] > median_wage_gap).astype(int)"
      ],
      "metadata": {
        "id": "SmLoNZTNf--V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = filtered_data[['grad_rate'] + [col for col in filtered_data.columns if col.startswith('source.label_')]]\n",
        "y = filtered_data['wage_gap_class']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKdWHh8LhOMa",
        "outputId": "818f407e-b64c-4d58-f095-1617aa7903b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.72\n",
            "Confusion Matrix:\n",
            "[[12  8]\n",
            " [ 2 14]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.60      0.71        20\n",
            "           1       0.64      0.88      0.74        16\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.75      0.74      0.72        36\n",
            "weighted avg       0.76      0.72      0.72        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 혼동행렬을 분석해 분류 성능 다각도로 평가"
      ],
      "metadata": {
        "id": "K4W0ozM4hpXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "print(\"혼동행렬:\")\n",
        "print(conf_matrix)\n",
        "print(f\"정확도(Accuracy): {accuracy:.2f}\")\n",
        "print(f\"정밀도(Precision): {precision:.2f}\")\n",
        "print(f\"재현율(Recall): {recall:.2f}\")\n",
        "print(f\"F1 점수(F1 Score): {f1:.2f}\")\n",
        "print(\"\\n분류 리포트(Classification Report):\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmQKkvHZhw3m",
        "outputId": "cbb5d660-4d75-4718-9122-4573645b92c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "혼동행렬:\n",
            "[[12  8]\n",
            " [ 2 14]]\n",
            "정확도(Accuracy): 0.72\n",
            "정밀도(Precision): 0.64\n",
            "재현율(Recall): 0.88\n",
            "F1 점수(F1 Score): 0.74\n",
            "\n",
            "분류 리포트(Classification Report):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.60      0.71        20\n",
            "           1       0.64      0.88      0.74        16\n",
            "\n",
            "    accuracy                           0.72        36\n",
            "   macro avg       0.75      0.74      0.72        36\n",
            "weighted avg       0.76      0.72      0.72        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying SMOTE (Oversampling)\n",
        "\n",
        "- Applying SMOTE improved the balance between classes.  \n",
        "- However, further improvement is needed to enhance the recall for Class 1.  "
      ],
      "metadata": {
        "id": "mnvqjJETjssD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# SMOTE 적용\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"혼동행렬:\")\n",
        "print(conf_matrix)\n",
        "print(f\"정확도(Accuracy): {accuracy:.2f}\")\n",
        "print(\"\\n분류 리포트(Classification Report):\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S522yl4JjNNl",
        "outputId": "a2bebbf0-4e03-4249-8bb0-9368b838e246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "혼동행렬:\n",
            "[[16  2]\n",
            " [ 7 11]]\n",
            "정확도(Accuracy): 0.75\n",
            "\n",
            "분류 리포트(Classification Report):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.89      0.78        18\n",
            "           1       0.85      0.61      0.71        18\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.77      0.75      0.75        36\n",
            "weighted avg       0.77      0.75      0.75        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost-Sensitive Logistic Regression Model Training"
      ],
      "metadata": {
        "id": "1kk73iDztB0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "class_weights =  {0: 1, 1: 2}\n",
        "\n",
        "cost_sensitive_logreg = LogisticRegression(class_weight=class_weights, random_state=42)\n",
        "cost_sensitive_logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = cost_sensitive_logreg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"정확도(Accuracy): {accuracy:.2f}\")\n",
        "print(\"혼동행렬:\")\n",
        "print(conf_matrix)\n",
        "print(\"분류 리포트:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mPWMKXXmHyw",
        "outputId": "3f679580-d252-46d6-b295-58a7bbbd59ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도(Accuracy): 0.75\n",
            "혼동행렬:\n",
            "[[10  8]\n",
            " [ 1 17]]\n",
            "분류 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.56      0.69        18\n",
            "           1       0.68      0.94      0.79        18\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.79      0.75      0.74        36\n",
            "weighted avg       0.79      0.75      0.74        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **When Recall for Class 1 is Crucial**:  \n",
        "  Cost-sensitive logistic regression is effective for problems where recall for Class 1 is critical.\n",
        "\n",
        "- **Performance Trade-Off for Class 0**:  \n",
        "  - For **Class 0 (Low Wage Gap)**:  \n",
        "    - Precision remained high at 91%, but recall dropped to 56%, leading to some false positive classifications.\n",
        "\n",
        "#### class_weights = {0: 1, 1: 3}\n",
        "### Adjusting Class Weights\n",
        "- This heavily prioritized Class 1 but was deemed unnecessary since the problem is not as critical as cases like disease diagnosis or fraud detection.\n",
        "- Final Adjustment:  \n",
        "  - Reset to `class_weights = {0: 1, 1: 2}` to balance the importance of both classes more fairly.\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "tqlRICgYmXLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 하지만 FN이 치명적인 상황(질병 진단, 사기 탐지 등)과 같은 상황은 아니라고 판단하여, 클래스 0과 1 모두 동일한 비중으로 중요하므로 다시 class_weights = ({0: 1, 1: 2})로 설정하였습니다.\n"
      ],
      "metadata": {
        "id": "TxqI7k2SrN0O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L6Umhqiy5SRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}